{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/USER/REPO/blob/main/kdd_project/notebooks/KDD_Credit_Card_Fraud.ipynb)\n\n# KDD: Credit Card Fraud Detection\n\n> Selection \u2192 Preprocessing \u2192 Transformation \u2192 Data Mining \u2192 Interpretation/Evaluation\n\n**Dataset**: Kaggle \u2014 Credit Card Fraud Detection (highly imbalanced)."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "!pip -q install pandas numpy scikit-learn matplotlib seaborn xgboost lightgbm imbalanced-learn joblib gradio fastapi uvicorn kaggle",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_absolute_error, r2_score, roc_auc_score, classification_report, confusion_matrix\nimport joblib\nPath('data').mkdir(exist_ok=True)\nPath('models').mkdir(exist_ok=True)\nPath('reports').mkdir(exist_ok=True)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# --- Kaggle download (make sure you've set up your Kaggle token) ---\n    # In Colab:\n    # from google.colab import files\n    # files.upload()  # upload kaggle.json\n    # !mkdir -p ~/.kaggle\n    # !cp kaggle.json ~/.kaggle/\n    # !chmod 600 ~/.kaggle/kaggle.json\n    !kaggle datasets download -d mlg-ulb/creditcardfraud -p data\n    !ls -lh data\n    # If a zip is downloaded, unzip it:\n    !python - << 'PY'\nimport zipfile, glob, os\nzips = glob.glob('data/*.zip')\nfor z in zips:\n    with zipfile.ZipFile(z) as f:\n        f.extractall('data')\n        print('unzipped', z)\nPY",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Selection\n- Define the subset of fields and time windows\n- Document inclusion/exclusion and data lineage"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import pandas as pd\nfrom pathlib import Path\n\ncsv = next((p for p in Path('data').glob('*.csv') if 'creditcard' in p.name.lower()), None)\ndf = pd.read_csv(csv) if csv else None\nprint('Rows/cols:', None if df is None else df.shape)\ndf.head() if df is not None else None",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Preprocessing\n- Handle missing values (this dataset often has none)\n- Sanity checks & label balance"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "if df is not None:\n    print(df.isna().sum().sum(), 'missing total')\n    print('Class balance:')\n    print(df['Class'].value_counts(normalize=True))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Transformation\n- Scaling, PCA (already done), resampling strategies (SMOTE, undersample)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, classification_report\n\nif df is not None:\n    X = df.drop(columns=['Class'])\n    y = df['Class']\n    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n    sm = SMOTE(random_state=42)\n    X_res, y_res = sm.fit_resample(X_tr, y_tr)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Data Mining\n- Train several classifiers; tune with CV\n- Compare ROC\u2011AUC, precision/recall on fraud class"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "if df is not None:\n    clf = LogisticRegression(max_iter=200)\n    clf.fit(X_res, y_res)\n    proba = clf.predict_proba(X_te)[:,1]\n    print('ROC-AUC:', roc_auc_score(y_te, proba))\n    print(classification_report(y_te, clf.predict(X_te)))\n    joblib.dump(clf, 'models/model.joblib')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Interpretation & Evaluation\n- Threshold analysis; cost matrix\n- Monitoring & drift plan; actionable insights"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}